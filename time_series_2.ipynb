{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Autoregression and Moving Average\n",
        "\n",
        "* Box-Jenkins (1976)\n",
        "* No economic theory. For fitting and prediction only."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Series Probability Model\n",
        "\n",
        "* $X(t,\\omega)$\n",
        "* For a fixed $t=1,\\ldots,T,$ $X(t,\\cdot)$ is a random variable\n",
        "* For a fixed $\\omega \\in \\Omega$, $X(\\cdot,\\omega)$ is a sequence\n"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ergodic Theorem \n",
        "\n",
        "If the time series $X(t,w)$ is strictly and stationary, and $E[ X(t,w) ] = \\mu$, then as $n\\to \\infty$, $$ n^{-1} \\sum_{t=1}^n X(t,w) \\stackrel{p}{\\to} \\mu, $$ In other words, $$ P\\left[ \\omega \\in \\Omega: \\bigg| \\frac{1}{n} \\sum_{t=1}^n X(t,w) - \\mu \\bigg| > \\epsilon \\right] \\to 0. $$\n",
        "\n",
        "Temporary average $ n^{-1} \\sum_{t=1}^n X_t $ converges to spatial average $E[ X(t,\\cdot) ] $."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Simple Models\n",
        "\n",
        "* White noise: $(e_t)_{t=-\\infty}^{\\infty}$:\n",
        "    * $E[e_t] = 0$, $E[e_t^2] = \\sigma_e^2$, and $E[e_t, e_s] = 0$ for all $t\\neq s$. "
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ARMA\n",
        "\n",
        "\n",
        "* AR(p) $$ y_t = \\mu + \\gamma_1 y_{t-1} + \\cdots \\gamma_p y_{t-p} + e_t $$\n",
        "* MA(q) $$ y_t = \\mu + e_t - \\theta_1 e_{t-1} - \\theta_q e_{t-q} + e_t $$\n",
        "* ARMA(p,q) $$(1-\\Gamma(L) ) y_t = \\mu + \\Theta (L) e_t$$\n",
        "\n",
        "Stationarity: in AR form whether all roots lies out of the unit cycle."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autocorrelation Pattern\n",
        "\n",
        "\n",
        "* MA(q): finite dependence\n",
        "* AR(1): geometric decline\n",
        "    * $E[ y_t ] = \\mu / (1-\\gamma_1)$\n",
        "    * $\\mathrm{var}[y_t] = \\sigma_e^2 / (1-\\gamma_1^2 )$\n",
        "    * $E[ y_t | y_{t-1} ] = \\mu + \\gamma_1 y_{t-1}$\n",
        "    * $\\mathrm{var}[y_t | y_{t-1} ] = \\sigma_e^2 $\n",
        "    \n"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n",
        "\n",
        "* ARIMA(p, r, q) $$(1-\\Gamma(L) ) \\Delta^r y_t = \\mu + \\Theta (L) e_t$$\n",
        "* Transform into stationary time series by taking logarithm and/or difference.\n",
        "* Fit ARMA(p,q)"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seasonality\n",
        "\n",
        "* Generated due to sampling frequency\n",
        "* Add dummies to control seasonality"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estimation\n",
        "\n",
        "* MLE for MA(q)\n",
        "* MLE for ARMA(p,q)\n",
        "* OLS for AR(p)"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Choice\n",
        "\n",
        "Information criteria. \n",
        "\n",
        "Let $k$ be the total number of slope coefficient in the model.\n",
        "\n",
        "* Akaike information criterion: $\\log( \\hat{\\sigma}^2 ) + 2\\times (k / T )$. \n",
        "    * Tend to overfit, but better for prediction\n",
        "* Bayesian information criterion: $\\log( \\hat{\\sigma}^2 ) + \\log(T) \\times (k / T )$\n",
        "    * Model selection consistent\n",
        "    \n",
        "Information criteria are not restricted to time series regressions. They are general statistical measures for model/variable selection."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AR(1) without drift\n",
        "\n",
        "$$y_t = \\gamma_1 y_{t-1} + e_t$$\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\sqrt{T} ( \\hat{\\gamma}_1 - \\gamma_1 ) & = \\sqrt{T} \\frac{ \\sum_{t=2}^T y_{t-1} e_t }{\\sum_{t=2}^{T} y_{t-1}^2 } \\\\\n",
        "& \\stackrel{d}{\\to} N \\bigg( 0, \\frac{  \\mathrm{var}[y_t] \\mathrm{var}[e_t] }{ (\\mathrm{var}[y_t])^2 }  \\bigg)\\\\\n",
        "& \\sim N \\bigg(0, \\frac{\\sigma_e^2}{ \\sigma_e^2 / (1-\\gamma_1^2) } \\bigg) \\\\\n",
        "& \\sim N\\big(0,  1-\\gamma_1^2  \\big) \n",
        "\\end{align*}\n",
        "$$\n",
        "\n",
        "\n",
        "        "
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens when $|\\gamma_1| \\to 1$?"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit Root\n",
        "\n",
        "* ARIMA(1,1,0) $$y_t = \\mu + y_{t-1} + e_t $$\n",
        "* Nonstationary\n",
        "* Brownian motion: normal innovation\n",
        "* Random walk"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implication\n",
        "* conditional and unconditional mean\n",
        "* conditional and unconditional variance\n",
        "* $h$-period ahead forecast"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The OLS estimator \n",
        "$$ T( \\hat{\\gamma}_1 - 1 ) \\stackrel{d}{\\to} \\mbox{ a stable distribution}.$$\n",
        "but the asymptotic distribution is not normal. "
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(quantmod, quietly = TRUE)\n",
        "getSymbols(\"^GSPC\") # S&P 500\n",
        "\n",
        "y = GSPC$GSPC.Close\n",
        "plot(y, type = \"l\")\n",
        "\n",
        "tail(y)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Null hypothesis: unit root.\n",
        "$$ \\Delta y_t = \\mu + (\\gamma_1 - 1 ) y_{t-1} + e_t = \\mu+ \\theta y_{t-1} + e_t$$\n",
        "where $ \\theta = \\gamma_1 - 1 $. Under the null, $\\theta = 0$.\n",
        "\n",
        "* The $t$-statistic is the test statistic for the Dicky-Fuller test.\n",
        "* Under the null, the $t$-statistic asymptotically follows a pivotal distribution.\n"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In this numerical example, the test does not reject the null.\n",
        "\n",
        "Notice: the test is one-sided."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(urca) # package for unit root and cointegration\n",
        "print( summary(ur.df(y, type = \"drift\", lags = 0) ) ) # y here is the S&P 500 index\n",
        "# the test does not reject the null of \"unit root\"\n",
        "# loosely speaking, it is evidence in support of random walk"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = arima.sim( model = list(ar =.8), n = 100)\n",
        "plot(y)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(urca); summary( ur.df( y, type = \"none\", selectlags = \"AIC\" ) ) # , "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(dynlm)\n",
        "\n",
        "DF.sim = function(ar){\n",
        "  Rep = 500\n",
        "  n = 100\n",
        "  \n",
        "  B.hat = rep(0, Rep)\n",
        "  \n",
        "  for (r in 1:Rep){\n",
        "    if (ar < 1) {\n",
        "      y = arima.sim( model = list(ar = ar), n = n)\n",
        "    } else if (ar == 1){\n",
        "      y = ts( cumsum( rnorm(n) ) )\n",
        "    }\n",
        "    reg.dyn = dynlm( y ~ L(y,1) )\n",
        "    B.hat[r] = coef(reg.dyn)[2]\n",
        "  }\n",
        "  return(B.hat)\n",
        "  print(\"simulation is done with ar = \", ar, \"\\n\")\n",
        "}\n",
        "\n",
        "\n",
        "B = DF.sim(1)\n",
        "plot(density(B), col = \"red\", xlim = c(0, 1.1))\n",
        "\n",
        "B = DF.sim(0.5)\n",
        "lines(density(B), col = \"blue\")\n",
        "\n",
        "B = DF.sim(0.9)\n",
        "lines( density(B), col = \"purple\" )\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "inputHidden": false,
        "outputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specification of DF test\n",
        "\n",
        "* The error term must be a white noise for the DF distribution\n",
        "* DF test's critical values vary with the specfication of drift and/or trend\n",
        "* Augmented Dicky-Fuller test: add more differenced lag terms"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other tests\n",
        "* Phillips-Perron test\n",
        "* KPSS test"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Series Filtering\n",
        "\n",
        "**Hodrick-Prescott filter**: Decompose a time series into *trend* and *cycle*\n",
        "\n",
        "$$\\hat{f}_{t}=\\arg \\min_{f_{t}}\\left\\{ \\sum_{t=1}^{n}\\left( y_{t}-f_{t}\\right)^{2}+\\lambda \\sum_{t=3}^{n}\\left( \\Delta ^{2}f_{t}\\right) ^{2}\\right\\}.$$\n",
        "    \n",
        "Hodrick Prescott (1980, 1997) suggest $\\lambda = 1600$ for quarterly data.\n",
        "$\\lambda = 1600$ is also the base of adjustment for different time series data frequency."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(mFilter)\n",
        "data(unemp)\n",
        "\n",
        "unemp.hp <- hpfilter(unemp)\n",
        "plot(unemp.hp)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boosted HP Filter\n",
        "\n",
        "* Phillips and Shi (2019): \"[Boosting: Why You Can Use the Hodrick-Prescott Filter](http://arxiv.org/abs/1905.00175),\" arXiv: 1905.00175\n",
        "* Chen and Shi (2019): R package **[BoostedHP](https://github.com/chenyang45/BoostedHP)**"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cointegration\n",
        "\n",
        "In a regression\n",
        "$$y_t = \\beta x_t  + e_t$$\n",
        "\n",
        "* If $y_t$ and $x_t$ are I(1) series\n",
        "* But a linear combination $e_t = y_t - \\beta x_t $ is I(0)\n",
        "\n",
        "then we say $y_t$ and $x_t$ are cointegrated."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data(denmark)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "period: Time index from 1974:Q1 until 1987:Q3.\n",
        "* `LRM`\tLogarithm of real money, M2.\n",
        "* `LRY`\tLogarithm of real income.\n",
        "* `LPY`\tLogarithm of price deflator.\n",
        "* `IBO`\tBond rate.\n",
        "* `IDE`\tBank deposit rate."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "-"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sjd <- denmark[, c(\"LRM\", \"LRY\", \"IBO\", \"IDE\")]\n",
        "matplot(sjd[,c(3,4)], type = \"l\") # Bond rate vs Bank deposit rate"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = sjd[,3]; x = sjd[,4]\n",
        "reg = lm(y~x)\n",
        "plot(residuals(reg), type = \"l\")\n",
        "abline( h = 0, lty = 2)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Source of Cointegration\n",
        "\n",
        "Common shock is the source of cointegration\n",
        "\n",
        "For example, if $y_{1t} = \\mu_1 + \\beta_1 t + e_{1t}$ and $y_{2t} = \\mu_2 + \\beta_2 t + e_{2t}$, where $e_{1t}$ and $e_{2t}$ are two white noises, then the cointegration vector must be $(1,\\theta)$ where $$\\theta = - \\beta_1 / \\beta_2.$$ The first coefficient 1 in this cointegration vector is for normalization.\n",
        "\n",
        "In this example, the common trend is a determistic one. In other examples, they can also share a stochastic trend."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cointegration \n",
        "\n",
        "More generally, for an $m$-vector $y_t$ is cointegrated if there exists a parameter vector $\\gamma$ (normalize the first element to be 1) such that $y_t ' \\gamma$ is I(0).\n",
        "\n"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The number of linear independent cointegrated vectors is called the **cointegration rank**. \n",
        "* The cointegration rank arranges from 1 to $m-1$."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error Correction Model\n",
        "\n",
        "Cliver Granger (Nobel prize 2001)\n",
        "\n",
        "Consider an ARDL(1,1) model\n",
        "$$ y_t  = \\mu + \\beta_0 x_t + \\beta_1 x_{t-1} + \\gamma_1 y_{t-1} + e_t. $$\n",
        "If $\\beta_0 = \\beta_1 = 0$, no *Granger causality* between $X$ and $Y$.\n",
        "When $X$ and $Y$ are both nonstationary, standard OLS inference is invalid.\n",
        "\n",
        "Subtract $y_{t-1}$ from both sides of \n",
        "$$\n",
        "\\begin{align*}\n",
        "\\Delta y_t & = \\mu + \\beta_0 x_t + \\beta_1 x_{t-1} + (\\gamma_1 -1 ) y_{t-1} + e_t  \\\\\n",
        "           & = \\mu + \\beta_0 \\Delta x_t + (\\beta_1 + \\beta_0) x_{t-1} + (\\gamma_1 -1 ) y_{t-1} + e_t  \\\\\n",
        "           & = \\mu + \\beta_0 \\Delta x_t + (\\gamma_1 -1 )( y_{t-1} - \\theta x_{t-1} ) + e_t  \n",
        "\\end{align*}\n",
        "$$\n",
        "where $\\theta =  (\\beta_1 + \\beta_0)/(1 - \\gamma_1)$.\n",
        "\n",
        "* A short-run relationship $\\Delta y_t \\sim \\mu + \\beta_0 \\Delta x_t + e_t$.\n",
        "* An long-run equilibrium error $(\\gamma_1 - 1 ) (y_{t-1} - \\theta x_{t-1} ) $.\n",
        "\n"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When $y_t$ is nonstationary\n",
        "\n",
        "\n",
        "* First difference recovers stationarity\n",
        "* Useful to identify spurious regression\n",
        "* Can be estimated either by OLS or by NLS"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictive Regression\n",
        "\n",
        "In the regression $$y_t = \\mu_y + \\beta_1 x_{t-1} + e_{yt}$$\n",
        "\n",
        "* $y_t$ is stationary \n",
        "* The predictor $x_t$ is highly persistent:\n",
        "$$x_t = \\mu_x + \\gamma x_{t-1} + e_{xt} $$ with $\\gamma$ is close to 1.\n",
        "\n",
        "* Even if $E[e_{yt} | x_{t-1} ] = 0$, OLS estimator of $\\beta_1$ is biased in finite sample when $e_{yt}$ and $e_{xt}$ are correlated (Stambaugh, 1999)."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Lee, Shi and Gao (2018): \"[On LASSO for Predictive Regression](https://arxiv.org/abs/1810.03140),\" arXiv: 1810.03140\n",
        "* Find new behavior of popular machine learning methods in predictive regression."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Autoregression (VAR)\n",
        "\n",
        "Christopher Sims (Nobel Prize 2011)\n",
        "\n",
        "An $m$-equation system\n",
        "$$ y_t = \\mu + \\Gamma_1 y_{t-1} + \\cdots + \\Gamma_p y_{t-p} + v_t $$\n",
        "where $E[ v_t v_t'] = \\Omega$.\n",
        "\n",
        "For prediction purpose, as a reduced-form of structural simultaneous equations."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estimation\n",
        "\n",
        "* For consistency and asymptotic normality, use OLS equation by equation\n",
        "* For asymptotic efficient, use multiple-equation GLS\n",
        "\n"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Invertibility\n",
        "\n",
        "Write the VAR(p) as\n",
        "$$ (I_m - \\Gamma (L) ) y_t = \\mu + v_t $$ \n",
        "where $\\Gamma(z) = \\Gamma_1 z + \\cdots + \\Gamma_p z^p$. \n",
        "\n",
        "Stable means that all roots of the $p$th order polynomial equation $$ I_m - \\Gamma(z)  = 0_m $$ lies out of the unit circle."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Impulse Response Function\n",
        "\n",
        "IRF characterizes the diffusion of an exogenous shock with the dynamic system.\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "y_t & = (I_m - \\Gamma(L) )^{-1} (\\mu + v_t) \\\\\n",
        "    & = \\bar{y} + \\left( v_t + \\sum_{i=1}^{\\infty} A_i v_{t-i} \\right)\n",
        "\\end{align*}\n",
        "$$ where $\\bar{y} = (I_m - \\Gamma(L) )^{-1} \\mu = ( I_m + \\sum_{i=1}^{\\infty} A_i ) \\mu $."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "library(tsDyn)\n",
        "data(barry)\n",
        "plot(barry)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## For VAR\n",
        "mod_var <- lineVar(barry, lag = 2)\n",
        "print(mod_var)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "irf_var = irf(mod_var, impulse = \"dolcan\", response = c(\"dolcan\", \"cpiUSA\", \"cpiCAN\"), boot = FALSE)\n",
        "# no matter stationary or not, OLS point estimator is always valid\n",
        "print(irf_var)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(irf_var)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## For VECM\n",
        "mod_VECM <- VECM(barry, lag = 2, estim=\"ML\", r=2)\n",
        "# VECM is better choice for standard inference when nonstationary time series is involved.\n",
        "print(mod_VECM)\n",
        "irf_vecm = irf(mod_VECM, impulse = \"dolcan\", response = c(\"dolcan\", \"cpiUSA\", \"cpiCAN\"), boot = FALSE)\n",
        "print(irf_vecm)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structural VAR\n",
        "\n",
        "* Unrestricted VAR: too many parameters? $m+p\\cdot m^2 + m(m+1)/2$\n",
        "* Use economic theory to reduce the number of unknown parameters"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VECM Representation\n",
        "\n",
        "Suppose there are $r$ cointegration relationship in $y_t$. For the $m$-equation VAR system \n",
        "$$y_t = \\Gamma y_{t-1} + e_t,$$ we can rewrite it as\n",
        "$$ \\Delta y_t = (\\Gamma - I_m) y_{t-1} + e_t = \\Pi y_{t-1} + e_t.$$\n",
        "\n",
        "* Since LHS is stationary, the $m\\times m$ matrix $\\Pi = \\Gamma - I_m$ on the RHS must only have rank at most $r$. \n",
        "* Otherwise, the RHS will be I(1) and the two sides of the equation are unbalanced.\n",
        "* VECM is the base for the cointegration rank test (Johansen, 1992)."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot(irf_vecm)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numerical Example: Johansen Test\n",
        "\n",
        "The result shows that there is only 1 cointegration relationship among the 4 time series."
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sjd.vecm = ca.jo(sjd, ecdet = \"const\", type=\"eigen\", K=2, spec=\"longrun\")\n",
        "summary(sjd.vecm)\n",
        "# the result rejects \"r = 0\", but do not reject \"r<=1,2,3\"\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Future of Time Series Study\n",
        "\n",
        "* Classical methods\n",
        "* Time series model for discrete choice model\n",
        "* Time series dimension of big data\n",
        "    * Unstructured data\n",
        "    * Panel data"
      ],
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      }
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernel_info": {
      "name": "ir"
    },
    "kernelspec": {
      "name": "ir",
      "language": "R",
      "display_name": "R"
    },
    "language_info": {
      "name": "R",
      "codemirror_mode": "r",
      "pygments_lexer": "r",
      "mimetype": "text/x-r-source",
      "file_extension": ".r",
      "version": "3.5.0"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}